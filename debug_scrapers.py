import asyncio
import logging
import sys
import argparse

# --- IMPORTS DE TUS SCRAPERS ---
# Aseg√∫rate de importar aqu√≠ todos los scrapers que vayas creando
from agenda_cultural.backend.scrapers.lum import LumScraper
from agenda_cultural.backend.scrapers.alianza_francesa import AlianzaFrancesaScraper
from agenda_cultural.backend.scrapers.bnp import BnpScraper
from agenda_cultural.backend.scrapers.ccpucp import CcpucpScraper
# from agenda_cultural.scrapers.ccpucp_scraper import CcpucpScraper (cuando lo tengas)

# --- MAPA DE SCRAPERS ---
# Aqu√≠ registras el nombre clave que usar√°s en la terminal y la Clase correspondiente
SCRAPERS = {
    "lum": LumScraper,
    "af": AlianzaFrancesaScraper,
    "bnp": BnpScraper,
    "ccpucp": CcpucpScraper,
}

# Configuraci√≥n de Logging para ver todo en la consola
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)


async def test_single_scraper(scraper_name: str):
    """Funci√≥n gen√©rica para probar cualquier scraper."""

    scraper_class = SCRAPERS.get(scraper_name)

    if not scraper_class:
        logger.error(f"‚ùå No existe el scraper '{scraper_name}'.")
        logger.info(f"Opciones disponibles: {list(SCRAPERS.keys())}")
        return

    print(f"\nüöÄ INICIANDO TEST: {scraper_name.upper()}...")

    try:
        # Instanciamos la clase din√°micamente
        scraper = scraper_class()

        # Ejecutamos
        movies = await scraper.get_movies()

        print("\nüé¨ RESULTADOS FINALIZADOS")
        print(f"Total encontrado: {len(movies)} pel√≠culas.")
        print("=" * 60)

        for i, movie in enumerate(movies, 1):
            print(f"\nüé• PEL√çCULA #{i}")
            print(f"   Title    : {movie.title}")
            print(f"   Date     : {movie.date}")
            print(f"   Location : {movie.location or 'N/A'}")
            print(f"   Center   : {movie.center}")
            print(f"   Link     : {movie.source_url}")
            print("-" * 30)

    except Exception as e:
        logger.critical(f"üí• El scraper fall√≥ con error: {e}", exc_info=True)


if __name__ == "__main__":
    # Configuraci√≥n de argumentos de l√≠nea de comandos
    parser = argparse.ArgumentParser(
        description="Herramienta de depuraci√≥n de scrapers."
    )
    parser.add_argument(
        "scraper", type=str, help="Nombre clave del scraper a probar (ej: lum, af)"
    )

    args = parser.parse_args()

    # Ejecutar
    asyncio.run(test_single_scraper(args.scraper))
