name: Ejecutar Scraper Local

on:
  workflow_dispatch:
  schedule:
    - cron: '0 19 * * *'

jobs:
  scrape:
    runs-on: [self-hosted, linux, local-scraper]

    steps:
    - name: Checkout c√≥digo
      uses: actions/checkout@v4

    - name: Sincronizar Entorno y Ejecutar
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        TMDB_TOKEN: ${{ secrets.TMDB_TOKEN }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: "us-east-1"
        ENABLE_CLOUDWATCH_LOGS: "true"
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        
        uv sync
        
        uv run playwright install chromium
        
        uv run run_scraper.py
