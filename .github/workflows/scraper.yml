name: Ejecutar Scraper Local

on:
  workflow_dispatch:
  schedule:
    - cron: '0 19 * * *'

jobs:
  scrape:
    runs-on: [self-hosted, linux, local-scraper]

    steps:
    - name: Checkout código
      uses: actions/checkout@v4

    - name: Preparar Túnel SSM
      run: |
        fuser -k 5433/tcp || true 
        
        ssh -o StrictHostKeyChecking=no -f -N -L 5433:${{ secrets.RDS_ENDPOINT }}:5432 aws        

        sleep 5

    - name: Sincronizar Entorno y Ejecutar
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        TMDB_TOKEN: ${{ secrets.TMDB_TOKEN }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: "us-east-1"
        ENABLE_CLOUDWATCH_LOGS: "true"
      run: |
        export PATH="$HOME/.local/bin:$PATH"
        uv sync
        uv run playwright install chromium
        uv run run_scraper.py
